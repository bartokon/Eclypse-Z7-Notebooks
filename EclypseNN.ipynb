{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:39:38.940611Z",
     "start_time": "2020-10-28T11:39:28.865491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "import pynq\n",
    "from pynq import Overlay\n",
    "from pynq import allocate\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:53:49.584332Z",
     "start_time": "2020-10-28T12:53:37.970587Z"
    }
   },
   "outputs": [],
   "source": [
    "class nn:\n",
    "    weights = list()\n",
    "    #dnet/dw -> dnetL1/dw5 x.outputs[0][0]\n",
    "    outputs = list()\n",
    "    #dout/dnet -> doutL1/dnetL1 outputs_transfer_derivative[1][0]\n",
    "    outputs_transfer_derivative = list()\n",
    "    inputs = list()\n",
    "    def __init__(self, weights):\n",
    "        self.weights = np.array(weights, dtype=np.float32)\n",
    "        layers_count, neurons_count, weights_count = self.weights.shape\n",
    "        self.outputs = np.zeros((layers_count, neurons_count), dtype=np.float32)\n",
    "        self.outputs_transfer_derivative = self.outputs.copy()\n",
    "        \n",
    "    def transfer_derivative(self, output):\n",
    "        if output > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        #return output*(1-output)\n",
    "    \n",
    "    def activation_function(self, output):\n",
    "        if output > 0:\n",
    "            return output\n",
    "        else:\n",
    "            return 0.000001\n",
    "        #return 1/(1+np.exp(-output))\n",
    "    \n",
    "    def calculate_error(self, target):\n",
    "        target = np.array(target, dtype=np.float32)\n",
    "        target_size = target.shape[0]\n",
    "        buf = 0\n",
    "        for i in range(target_size):\n",
    "            buf = buf + ((self.outputs[self.outputs.shape[0]-1][i] - target[i])**2)/2\n",
    "        return buf\n",
    "    \n",
    "    def output_error(self, target):\n",
    "        target = np.array(target, dtype=np.float32)\n",
    "        target_size = target.shape[0]\n",
    "        buf = np.zeros(target.shape)\n",
    "        for i in range(target_size):\n",
    "            buf[i] = (self.outputs[self.outputs.shape[0]-1][i] - target[i])\n",
    "        return buf\n",
    "    \n",
    "    def calculate_delta_outputs(self, target, neuron_nb):\n",
    "        buf = self.output_error(target)\n",
    "        s = 0 \n",
    "        for w in range(self.weights.shape[0]):\n",
    "            wyn = buf[w]*self.outputs_transfer_derivative[self.weights.shape[0]-1][w]*self.weights[self.weights.shape[0]-1][w][neuron_nb]\n",
    "            s = s + wyn\n",
    "            buf[w] = wyn\n",
    "        \n",
    "        return buf \n",
    "    \n",
    "    #{l}{n}{w}\n",
    "    def forward_propagate(self, inputs):\n",
    "        output_buf = inputs\n",
    "        layers_count, neurons_count, weights_count = self.weights.shape\n",
    "        self.inputs = inputs\n",
    "        #krnl\n",
    "        for l in range(layers_count):\n",
    "            for_prop = output_buf.copy()\n",
    "            for n in range(neurons_count):\n",
    "                activation_value = 0\n",
    "                for w in range(weights_count-1):\n",
    "                    activation_value = activation_value + self.weights[l][n][w] * output_buf[w]\n",
    "                activation_value = activation_value + self.weights[l][n][w+1]\n",
    "                for_prop[n] = self.activation_function(activation_value)\n",
    "                self.outputs_transfer_derivative[l][n] = self.transfer_derivative(for_prop[n])\n",
    "            output_buf = for_prop.copy()\n",
    "            self.outputs[l][:] = output_buf.copy()\n",
    "        #krnl\n",
    "     \n",
    "    def backpropagationG(self, target, lr):\n",
    "        layers_count, neurons_count, weights_count = self.weights.shape\n",
    "        wnew = self.weights.copy()\n",
    "        self.outputs = np.insert(self.outputs, 0, values=self.inputs, axis=0)\n",
    "        #krnl\n",
    "        l = layers_count\n",
    "        en = self.output_error(target)\n",
    "        #krnl\n",
    "\n",
    "        for n in range(neurons_count): \n",
    "            for w in range(weights_count-1):              \n",
    "                wnew[l-1][n][w] = self.weights[l-1][n][w] - lr*en[n] * self.outputs_transfer_derivative[l-1][n] * self.outputs[l-1][w] #self.outputs[l-1][w]\n",
    "                               \n",
    "        l = layers_count-1\n",
    "        for n in range(neurons_count):\n",
    "            en = self.calculate_delta_outputs(target, n)\n",
    "            for w in range(weights_count-1):\n",
    "                wnew[l-1][n][w] = self.weights[l-1][n][w] - lr* sum(en) * self.outputs_transfer_derivative[l-1][n] * self.outputs[l-1][w] #self.outputs[l-1][w]\n",
    "                \n",
    "        #krnl\n",
    "        self.outputs = np.delete(self.outputs, 0, axis=0)\n",
    "        self.weights = wnew.copy()\n",
    "        \n",
    "    def nn_software_trainer(self, iterations, lr):\n",
    "\n",
    "        img_white_vector = np.ones((self.inputs.shape), np.float32)\n",
    "        img_black_vector = np.zeros((self.inputs.shape), np.float32)\n",
    "\n",
    "        inputsw = img_white_vector\n",
    "        goldenw = np.array([3 for i in range(img_white_vector.shape[0])])\n",
    "        inputsb = img_black_vector\n",
    "        goldenb = np.array([0 for i in range(img_black_vector.shape[0])])\n",
    "        errordataw = {}\n",
    "        errordatab = {}\n",
    "\n",
    "        for i in range(iterations):\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            self.forward_propagate(inputsw)\n",
    "            self.backpropagationG(goldenw, lr) \n",
    "            errordataw[i]=(self.calculate_error(goldenw))\n",
    "            print(f\"ERRORZw: {i} {self.calculate_error(goldenw)}\")\n",
    "            print(f\"Max of outputs: {np.average(self.outputs[1])}\")\n",
    "\n",
    "            self.forward_propagate(inputsb)\n",
    "            self.backpropagationG(goldenb, lr) \n",
    "            errordatab[i]=(self.calculate_error(goldenb))\n",
    "            print(f\"ERRORZb: {i} {self.calculate_error(goldenb)}\")\n",
    "            print(f\"Max of outputs: {np.average(self.outputs[1])}\")\n",
    "\n",
    "        lists = sorted(errordataw.items()) # sorted by key, return a list of tuples\n",
    "        x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "\n",
    "        lists = sorted(errordatab.items()) # sorted by key, return a list of tuples\n",
    "        x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "\n",
    "class nn_hw_accel:\n",
    "#31 speedup (192 image vector)\n",
    "    def __init__(self, weights):\n",
    "        self.nn_overlay = Overlay(\"/home/xilinx/jupyter_notebooks/design_neural.bit\")\n",
    "        \n",
    "        print(\"Turning off leds...\")\n",
    "        self.led_0_control(0)\n",
    "        self.led_1_control(0)\n",
    "        \n",
    "        print(\"Translating weight list to numpy array...\")\n",
    "        self.w_state = 0\n",
    "        w = np.array(weights, dtype=np.float32)\n",
    "        layers_count, neurons_count, weights_count = w.shape\n",
    "        self.layers_count = layers_count\n",
    "        self.neurons_count = neurons_count\n",
    "        self.weights_count = weights_count\n",
    "        \n",
    "        print(\"Allocating dma...\")\n",
    "        self.target = allocate(shape=(768), dtype=np.float32)\n",
    "        self.calc_error = allocate(shape=(768), dtype=np.float32)\n",
    "        \n",
    "        print(\"Allocating weights...\")\n",
    "        self.weights_new = allocate((2, 768, 769), dtype=np.float32)\n",
    "        self.weights = allocate((2, 768, 769), dtype=np.float32) \n",
    "        for x in range(w.shape[0]):\n",
    "            for y in range(w.shape[1]):\n",
    "                for z in range(w.shape[2]):\n",
    "                    self.weights[x][y][z]=weights[x][y][z]\n",
    "                    self.weights_new[x][y][z]=weights[x][y][z]\n",
    "           \n",
    "        print(\"Allocating neural network outputs...\")    \n",
    "        self.outputs = allocate(shape=(3, 768), dtype=np.float32)\n",
    "        print(\"Setting physical adresses for IP's\")\n",
    "        \n",
    "        print(\"Forward propagation IP\")\n",
    "        lk = self.float_to_uint(0.0)\n",
    "        self.nn_overlay.forward_propagate_L2_0.register_map.leak = lk\n",
    "        self.nn_overlay.forward_propagate_L2_0.register_map.weight = self.weights.physical_address\n",
    "        self.nn_overlay.forward_propagate_L2_0.register_map.output_r = self.outputs.physical_address\n",
    "        self.nn_overlay.forward_propagate_L2_0.register_map.m_lay = layers_count\n",
    "        self.nn_overlay.forward_propagate_L2_0.register_map.m_neu = neurons_count\n",
    "        \n",
    "        print(\"Back propagation IP\")\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.m_lay = layers_count\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.m_neu = neurons_count\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.new_weight = self.weights_new.physical_address\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.weight = self.weights.physical_address\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.output_offset = self.outputs.physical_address\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.en_offset = self.calc_error.physical_address\n",
    "        print(\"Finished\")\n",
    "        \n",
    "    def calculate_error(self, target):\n",
    "        target = np.array(target, dtype=np.float32)\n",
    "        target_size = target.shape[0]\n",
    "        buf = 0\n",
    "        for i in range(target_size):\n",
    "            buf = buf + ((self.outputs[2][i] - target[i])**2)/2\n",
    "        return buf\n",
    "    \n",
    "    def output_error(self):\n",
    "        self.nn_overlay.axi_dma_target.sendchannel.transfer(self.target)\n",
    "        self.nn_overlay.axi_dma_nn_out.sendchannel.transfer(self.outputs[2])\n",
    "        self.nn_overlay.axi_dma_out_r.recvchannel.transfer(self.calc_error)\n",
    "        self.nn_overlay.axi_dma_nn_out.sendchannel.wait()\n",
    "        self.nn_overlay.axi_dma_target.sendchannel.wait()\n",
    "        self.nn_overlay.axi_dma_out_r.recvchannel.wait()\n",
    "        #free running\n",
    "\n",
    "    def float_to_uint(self, f):\n",
    "        return int(struct.unpack('<I', struct.pack('<f', f))[0])\n",
    "    \n",
    "    def uint_to_float(self, f):\n",
    "        return float(struct.unpack('<f', struct.pack('<I', f))[0])\n",
    "\n",
    "    def backpropagationG(self, targ, lr):\n",
    "        for i in range(targ.shape[0]):\n",
    "            self.target[i] = targ[i]\n",
    "            \n",
    "        #krnl_dma\n",
    "        self.output_error()\n",
    "        #krnl_dma\n",
    "        \n",
    "        #krnl\n",
    "        le_lr = self.float_to_uint(lr)\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.learning_rate = le_lr\n",
    "        self.nn_overlay.back_propagate_L2_New_0.register_map.CTRL.AP_START = 1\n",
    "        #krnl\n",
    "        while True:\n",
    "            done_idle = self.nn_overlay.back_propagate_L2_New_0.register_map.CTRL.AP_IDLE\n",
    "            done_start = self.nn_overlay.back_propagate_L2_New_0.register_map.CTRL.AP_START\n",
    "            if (done_idle == 1 and done_start == 0):\n",
    "                break\n",
    "            print(f\"Waiting...\")        \n",
    "        \n",
    "    def forward_propagate(self, inputs):\n",
    "        inputs = np.array(inputs, dtype=np.float32)\n",
    "        for x in range(inputs.shape[0]):\n",
    "            self.outputs[0][x] = inputs[x]\n",
    "    \n",
    "        #krnl\n",
    "        self.nn_overlay.forward_propagate_L2_0.register_map.CTRL.AP_START = 1\n",
    "        #krnl\n",
    "    \n",
    "    def led_1_control(self, to_leds):\n",
    "        #Use this to manipulate leds\n",
    "        actual_led_vals = self.nn_overlay.axi_gpio_0.channel2.read()\n",
    "        led_val = (actual_led_vals & 0b000111) | to_leds << 3\n",
    "        self.nn_overlay.axi_gpio_0.channel2.write(led_val, 0xffffff)\n",
    "        \n",
    "    def led_0_control(self, to_leds):\n",
    "        #Use this to manipulate leds\n",
    "        actual_led_vals = self.nn_overlay.axi_gpio_0.channel2.read()\n",
    "        led_val = (actual_led_vals & 0b111000) | to_leds\n",
    "        self.nn_overlay.axi_gpio_0.channel2.write(led_val, 0xffffff)\n",
    "    \n",
    "    def button_0_control(self):\n",
    "        button_status = self.nn_overlay.axi_gpio_0.channel1.read()\n",
    "        return button_status\n",
    "    \n",
    "def setup_camera():\n",
    "    for id in range(8):     \n",
    "        camera_module = cv2.VideoCapture(id)\n",
    "        if (camera_module.isOpened() == True):\n",
    "            return camera_module\n",
    "        else:\n",
    "            print(f\"No camera found on {id}...\")\n",
    "            continue\n",
    "    raise Exception(\"No camera has been found or camera is already connected\")\n",
    "    \n",
    "def get_camera_frame(camera_module, width = 32, height = 32):\n",
    "    dsize = (width, height)\n",
    "    failed = 0\n",
    "    while True:\n",
    "        ret, frame = camera_module.read()  \n",
    "        if (ret == False): \n",
    "            print(\"Failed to get frame!\")\n",
    "            failed += 1\n",
    "            clear_output(wait=True)\n",
    "            time.sleep(0.5)\n",
    "            if (failed > 8):\n",
    "                break\n",
    "        else: \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            resized_frame = cv2.resize(frame, dsize)\n",
    "            return resized_frame\n",
    "        \n",
    "def normalise_image(image):\n",
    "    #Image normalisation\n",
    "    image = image/255\n",
    "    return image\n",
    "\n",
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    #print(f\"frame.shape: {frame.shape}\")\n",
    "    \n",
    "def generate_weights_based_on_image(img_vector):\n",
    "    w = np.empty(shape=(2, img_vector.shape[0], img_vector.shape[0]+1), dtype=np.float32)\n",
    "    for l in range(w.shape[0]):\n",
    "            for n in range(w.shape[1]):\n",
    "                w[l][n] = np.random.uniform(low=0.01, high=0.15, size=(w.shape[2],))\n",
    "    return w        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-28T12:53:39.532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To leds: 2\n",
      "NN output: 2.336979866027832\n"
     ]
    }
   ],
   "source": [
    "#This is for camera learning :)\n",
    "#cam_module = setup_camera()\n",
    "#Gaussian blur\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "#Flatten image and normalise\n",
    "image = get_camera_frame(cam_module, width = 12, height = 12)\n",
    "img_vector = np.reshape(image.astype(np.float32), -1)\n",
    "img_vector = normalise_image(img_vector)\n",
    "print(f\"Image shape: {img_vector.shape[0]}\")\n",
    "#Generate weights\n",
    "weights = generate_weights_based_on_image(img_vector)\n",
    "\n",
    "xn = nn_hw_accel(weights)\n",
    "goldenw = np.array([3 for i in range(img_vector.shape[0])], dtype=np.float32)\n",
    "goldenb = np.array([0 for i in range(img_vector.shape[0])], dtype=np.float32)\n",
    "while True:\n",
    "    #time.sleep(0.1)\n",
    "    clear_output(wait=True)\n",
    "    image = get_camera_frame(cam_module, width = 16, height = 1)\n",
    "    image = cv2.filter2D(image,-1,kernel)\n",
    "    img_vector = np.reshape(image.astype(np.float32), -1)\n",
    "    img_vector = normalise_image(img_vector)\n",
    "    xn.forward_propagate(img_vector)\n",
    "    #If button one is pressed learn new image pattern to light up leds\n",
    "    if (xn.button_0_control() == 1):\n",
    "        #blue\n",
    "        print(\"White\")\n",
    "        xn.led_1_control(to_leds=1)\n",
    "        xn.backpropagationG(goldenw, 0.01)            \n",
    "    elif (xn.button_0_control() == 2):\n",
    "        #green\n",
    "        print(\"Black\")\n",
    "        xn.led_1_control(to_leds=2)\n",
    "        xn.backpropagationG(goldenb, 0.01)\n",
    "    elif (xn.button_0_control() == 3):\n",
    "        xn.led_1_control(to_leds=0b000)\n",
    "        break\n",
    "    else: \n",
    "        xn.led_1_control(to_leds=0b000)\n",
    "    to_L = np.int(np.round(np.average(xn.outputs[2][0:img_vector.shape[0]])))\n",
    "    if (to_L > 3):\n",
    "        to_L = 3\n",
    "    elif (to_L < 0):\n",
    "        to_L = 0\n",
    "        \n",
    "    xn.led_0_control(to_leds=to_L)\n",
    "    print(f\"To leds: {to_L}\")\n",
    "    print(f\"NN output: {np.average(xn.outputs[2][0:img_vector.shape[0]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:10:51.877760Z",
     "start_time": "2020-10-28T12:09:04.233702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To leds: 0\n",
      "NN output: 0.0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    #time.sleep(0.1)\n",
    "    clear_output(wait=True)\n",
    "    image = get_camera_frame(cam_module, width = 16, height = 1)\n",
    "    image = cv2.filter2D(image,-1,kernel)\n",
    "    img_vector = np.reshape(image.astype(np.float32), -1)\n",
    "    img_vector = normalise_image(img_vector)\n",
    "    xn.forward_propagate(img_vector)\n",
    "    #If button one is pressed learn new image pattern to light up leds\n",
    "    if (xn.button_0_control() == 1):\n",
    "        #blue\n",
    "        print(\"White\")\n",
    "        xn.led_1_control(to_leds=1)\n",
    "        xn.backpropagationG(goldenw, 0.04)            \n",
    "    elif (xn.button_0_control() == 2):\n",
    "        #green\n",
    "        print(\"Black\")\n",
    "        xn.led_1_control(to_leds=2)\n",
    "        xn.backpropagationG(goldenb, 0.04)\n",
    "    elif (xn.button_0_control() == 3):\n",
    "        xn.led_1_control(to_leds=0b000)\n",
    "        break\n",
    "    else: \n",
    "        xn.led_1_control(to_leds=0b000)\n",
    "    to_L = np.int(np.round(np.average(xn.outputs[2][0:img_vector.shape[0]])))\n",
    "    if (to_L > 3):\n",
    "        to_L = 3\n",
    "    elif (to_L < 0):\n",
    "        to_L = 0\n",
    "        \n",
    "    xn.led_0_control(to_leds=to_L)\n",
    "    print(f\"To leds: {to_L}\")\n",
    "    print(f\"NN output: {np.average(xn.outputs[2][0:img_vector.shape[0]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:11.302610Z",
     "start_time": "2020-10-28T12:00:11.222789Z"
    }
   },
   "source": [
    "xn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T20:08:03.382208Z",
     "start_time": "2020-10-22T20:07:55.727395Z"
    }
   },
   "outputs": [],
   "source": [
    "#Led blinker\n",
    "while True:\n",
    "    for i in range(8): \n",
    "        time.sleep(1)\n",
    "        xn.led_0_control(to_leds=0)\n",
    "        xn.led_1_control(to_leds=i-1)\n",
    "        time.sleep(1)\n",
    "        xn.led_1_control(to_leds=0)\n",
    "        xn.led_0_control(to_leds=i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 280,
   "position": {
    "height": "121px",
    "left": "1541px",
    "right": "20px",
    "top": "134px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
